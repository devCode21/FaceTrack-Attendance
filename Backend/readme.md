# FaceAttendance Backend


# ğŸ“Œ Overview

This backend receives classroom **videos or images**, processes them using a deep learning pipeline, identifies students through face embeddings, and updates attendance for a selected course.

**Key Highlights:**

* No videos stored â†’ privacy & low cost
* Works on low-compute machines
* Frame skipping, model selection, and similarity scoring carefully optimized
* Clean FastAPI backend + MongoDB

---

# ğŸ“‚ Folder Structure

```
backend/
 â”œâ”€â”€ app.py
 â”œâ”€â”€ src/
 â”‚    â”œâ”€â”€ components/
 â”‚    â”œâ”€â”€ utils/
 â”‚    â”œâ”€â”€ pipeline/
 â”‚    â””â”€â”€ database/
 â”œâ”€â”€ test/
 â””â”€â”€ requirements.txt
```

---

# ğŸ§  Face Recognition Pipeline (Full Context)

The backend uses a **3-stage deep learning pipeline** followed by embedding matching.

## **1ï¸âƒ£ YOLO11n â€” Face Detection**

We tested multiple detectors and finalized **YOLO11n** because:

* Excellent **speedâ€“accuracy trade-off**
* Works well on **CPU-level hardware**
* Faster than RetinaNet with similar accuracy
* Other YOLO variants gave slightly better accuracy but were slower

ğŸ‘‰ **Final decision:** YOLO11n is the best for real-time attendance.

## **2ï¸âƒ£ MTCNN â€” Face Alignment**

Faces in classroom videos are often tilted or partially rotated.

* MTCNN aligns faces properly
* Ensures consistent FaceNet embeddings
* light wieght model for alignment 

## **3ï¸âƒ£ FaceNet â€” Embedding Generation**

We create a **512-dimension embedding** for each face.

* Stable identity representation
* Works reliably even with low-resolution classroom frames

## **4ï¸âƒ£ Cosine Similarity â€” Identity Matching**

We tested different similarity measures:

* Euclidean (L2)
* Manhattan
* Dot Product
* Cosine Similarity

Cosine gave **the best separation between different students** during testing on our small dataset.

ğŸ‘‰ **Threshold used:** `0.80`

A match is valid if:

```
cosine_similarity >= 0.80
```

During testing, we experimented with different cosine similarity thresholds. When the threshold was set below 0.80, the number of false positives increased significantly, meaning the system started marking the wrong students as present. Even though lower thresholds improved true positive detection, the false positives were too high to use in a real classroom environment.

To keep the system reliable and avoid incorrect attendance marks, we decided to prioritize reducing false positives, even if it meant compromising a bit on true positive rates.
Therefore, the threshold 0.80 was

## **5ï¸âƒ£ Frame Skipping â€” Every 30th Frame**

Due to limited hardware (no GPU):

* Processing every frame was too slow
* Skipping too many frames missed faces

We found **30th frame** to be the ideal balance (still experminting on it ):

* Fast enough to process full classroom videos
* Still captures each student multiple times

---

# ğŸ§ª Model Experiments â€” Full Reasoning

This section includes everything we tested and why we kept or removed each model.

## **ğŸ”¹ EDSR (Super Resolution)**

Goal: Improve face quality â†’ improve embeddings.

**Result:**

* Slight improvement in accuracy
* BUT extremely slow
* Too heavy for real-time inference
* CPU-only machine couldnâ€™t handle it

ğŸ‘‰ **Rejected** due to speed.

---

## **ğŸ”¹ RetinaNet (Face Detection)**

Goal: Replace YOLO, see if accuracy improves.

**Result:**

* Accuracy similar to YOLO11n
* Slower detection
* No real accuracy benefit

ğŸ‘‰ **Rejected** because YOLO11n gives same output but much faster.

---

## **ğŸ”¹ YOLO11n (Final Choice)**

* Good accuracy
* Very fast
* Works well without GPU

ğŸ‘‰ **Selected as final detection model.**

---

# ğŸ”¬ Qualitative Benchmarks (Based on Observations)

Since we didnâ€™t have strong hardware (GPU), we used **practical, observed benchmarks**:

### **Detection Speed**

* **YOLO11n** â†’ Fastest detectable performance on our setup
* **RetinaNet** â†’ Noticeably slower

### **Embedding Quality**

* **FaceNet** performed consistently well
* EDSR improved quality but slowed system drastically

### **Matching Accuracy**

* Cosine similarity gave the most stable results
* Threshold 0.80 minimized false positives

### **End-to-end Pipeline Speed**

* Processing every frame â†’ too slow
* Every 10th frame â†’ too many mismatches
* **Every 30th frame â†’ perfect balance**

These decisions are practical, based on multiple test videos and real constraints.

---

# ğŸ—„ï¸ Database (MongoDB)

The backend uses two collections.

## **Course Collection**

Stores teacherâ€™s course.

```
{
  _id: ObjectId,
  name: "teacher_name",
  course_name: "CourseTitle",
  password: "hashed_password",
  class_object_id: ObjectId
}
```

## **Class Collection**

Stores class metadata + student embeddings.

```
{
  _id: ObjectId,
  className: "ECE_3A",
  class_id: "ID123",
  embeddings: [
    {
      student_name: "Ravi",
      embedding: [...128-dim vector...],
      student_id: "S101"
    }
  ]
}
```

---

# ğŸ”— API Endpoints

### **POST /attendance_image/{course_id}**

Process a single image and update attendance.

### **POST /attendance_data/{course_id}**

Process a classroom video and update attendance.

### **POST /login_existing_course**

Teacher login.

### **POST /Create_New_Course**

Create a new course.

---

# ğŸ”§ Running Locally

```
uvicorn app:app --reload
```

---

# ğŸ³ Docker Setup

Coming soon (not implemented yet).

---

# â˜ï¸ AWS Deployment

Coming soon (planned for EC2 + Docker).

---

# ğŸ”® Future Improvements

* Use ArcFace for better embeddings
* Convert models to ONNX for speed
* Add GPU support when available
* Real-time face tracking
* Live dashboard for attendance

---

# ğŸ¤ Contributing

Suggestions welcome.

# ğŸ“„ License

MIT / your choice.
